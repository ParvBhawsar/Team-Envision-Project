{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20f16873",
   "metadata": {},
   "source": [
    "# 3-Class Chest X-ray Classifier (Normal / Pneumonia / Tuberculosis)\n",
    "\n",
    "**Fast, beginner-friendly baseline** that fine-tunes a pretrained CNN and produces balanced metrics + clear visualizations (confusion matrix, ROC/PR curves, Grad-CAM).\n",
    "\n",
    "> **Note:** This notebook is for educational/recruitment purposes and **not a medical device**. Do not use for clinical decisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a3269b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running on Kaggle, most libs are available; installing grad-cam just in case.\n",
    "%pip -q install timm torchmetrics grad-cam --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f03d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, time, math, json, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve\n",
    "\n",
    "import timm  # optional (not strictly needed for resnet18)\n",
    "from torchmetrics.functional import accuracy\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa852d5e",
   "metadata": {},
   "source": [
    "## Data\n",
    "This notebook assumes a Kaggle dataset with the following structure (train/val/test folders already provided). We **ignore** the `Covid-19` class and keep the three classes we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0422b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to your dataset root.\n",
    "# On Kaggle, after adding the dataset \"chest-xray-pneumoniacovid19tuberculosis\",\n",
    "# the path is typically:\n",
    "data_root = Path('/kaggle/input/chest-xray-pneumoniacovid19tuberculosis')\n",
    "\n",
    "# If you're on Colab, set your own path accordingly.\n",
    "if not data_root.exists():\n",
    "    print(\"WARNING: data_root not found. Set 'data_root' to your dataset path and re-run this cell.\")\n",
    "\n",
    "wanted = {'normal', 'pneumonia', 'tuberculosis'}  # target class names (lowercase match)\n",
    "splits = ['train', 'val', 'test']\n",
    "\n",
    "def infer_class_name(p: Path):\n",
    "    \"\"\"Map a folder name to our desired class name in lowercase.\"\"\"\n",
    "    name = p.name.lower().strip()\n",
    "    # Normalize a few common variants\n",
    "    name = name.replace(' ', '').replace('_', '').replace('-', '')\n",
    "    if 'normal' in name:\n",
    "        return 'normal'\n",
    "    if 'pneumonia' in name:\n",
    "        return 'pneumonia'\n",
    "    if 'tuberculosis' in name or name.startswith('tb'):\n",
    "        return 'tuberculosis'\n",
    "    if 'covid' in name:\n",
    "        return 'covid'\n",
    "    return name  # default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dff634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms, datasets\n",
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.85, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(5),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1, 0.05),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "eval_tfms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "class FilteredImageFolder(datasets.ImageFolder):\n",
    "    def __init__(self, root, transform=None, target_transform=None, wanted_classes=None):\n",
    "        super().__init__(root=root, transform=transform, target_transform=target_transform)\n",
    "        if wanted_classes is None:\n",
    "            wanted_classes = {'normal','pneumonia','tuberculosis'}\n",
    "        self.class_to_name = {i: infer_class_name(Path(c)) for i, c in enumerate(self.classes)}\n",
    "        keep_indices = [i for i, c in enumerate(self.classes) if infer_class_name(Path(c)) in wanted_classes]\n",
    "        kept_names = sorted(list({infer_class_name(Path(self.classes[i])) for i in keep_indices}))\n",
    "        self.name_to_newidx = {name: j for j, name in enumerate(kept_names)}\n",
    "        self.new_classes = kept_names\n",
    "\n",
    "        new_samples = []\n",
    "        for (path, orig_idx) in self.samples:\n",
    "            name = self.class_to_name[orig_idx]\n",
    "            if name in wanted_classes:\n",
    "                new_samples.append((path, self.name_to_newidx[name]))\n",
    "        self.samples = new_samples\n",
    "        self.targets = [t for _, t in self.samples]\n",
    "        self.classes = self.new_classes\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "\n",
    "def make_loader(split, transform):\n",
    "    root = data_root / split\n",
    "    ds = FilteredImageFolder(root=root, transform=transform, wanted_classes={'normal','pneumonia','tuberculosis'})\n",
    "    return ds, DataLoader(ds, batch_size=BATCH_SIZE, shuffle=(split=='train'), num_workers=2, pin_memory=True)\n",
    "\n",
    "train_ds, train_loader = make_loader('train', train_tfms)\n",
    "val_ds,   val_loader   = make_loader('val',   eval_tfms)\n",
    "test_ds,  test_loader  = make_loader('test',  eval_tfms)\n",
    "\n",
    "print(\"Classes:\", train_ds.classes)\n",
    "print(\"Train/Val/Test sizes:\", len(train_ds), len(val_ds), len(test_ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter(train_ds.targets)\n",
    "num_classes = len(train_ds.classes)\n",
    "class_counts = [counts.get(i, 0) for i in range(num_classes)]\n",
    "class_weights = [0 if c==0 else (sum(class_counts)/ (num_classes * c)) for c in class_counts]\n",
    "class_weights_tensor = torch.tensor(class_weights, dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Class counts:\", dict(zip(train_ds.classes, class_counts)))\n",
    "print(\"Class weights:\", dict(zip(train_ds.classes, [round(w,3) for w in class_weights])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad860fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using torchvision's ResNet18 for simplicity + speed\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "\n",
    "weights = ResNet18_Weights.DEFAULT\n",
    "model = resnet18(weights=weights)\n",
    "\n",
    "# Replace the classifier head for 3 classes + add Dropout for regularization\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(in_features, 3)\n",
    ")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss (with label smoothing) + optimizer + scheduler\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.05, weight=class_weights_tensor)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "EPOCHS = 8\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# Optionally freeze the backbone to speed up\n",
    "# for p in list(model.parameters())[:-2]:\n",
    "#     p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab150b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def run_epoch(dataloader, train=True):\n",
    "    model.train(train)\n",
    "    total_loss, total_correct, total = 0.0, 0, 0\n",
    "    all_targets, all_preds = [], []\n",
    "    for imgs, labels in dataloader:\n",
    "        imgs, labels = imgs.to(device), labels.to(device)\n",
    "        if train:\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "        with torch.set_grad_enabled(train):\n",
    "            logits = model(imgs)\n",
    "            loss = criterion(logits, labels)\n",
    "            if train:\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        total_correct += (pred == labels).sum().item()\n",
    "        total += imgs.size(0)\n",
    "        all_targets.extend(labels.detach().cpu().numpy().tolist())\n",
    "        all_preds.extend(pred.detach().cpu().numpy().tolist())\n",
    "    acc = total_correct / max(total,1)\n",
    "    f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "    return total_loss/max(total,1), acc, f1\n",
    "\n",
    "history = {'train_loss':[], 'val_loss':[], 'train_acc':[], 'val_acc':[], 'train_f1':[], 'val_f1':[]}\n",
    "\n",
    "best_val_f1, best_state, patience, patience_ctr = -1, None, 2, 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    tr_loss, tr_acc, tr_f1 = run_epoch(train_loader, train=True)\n",
    "    va_loss, va_acc, va_f1 = run_epoch(val_loader, train=False)\n",
    "    scheduler.step()\n",
    "\n",
    "    history['train_loss'].append(tr_loss); history['val_loss'].append(va_loss)\n",
    "    history['train_acc'].append(tr_acc);   history['val_acc'].append(va_acc)\n",
    "    history['train_f1'].append(tr_f1);     history['val_f1'].append(va_f1)\n",
    "\n",
    "    print(f\"Epoch {epoch:02d} | train loss {tr_loss:.4f} acc {tr_acc:.3f} f1 {tr_f1:.3f} || val loss {va_loss:.4f} acc {va_acc:.3f} f1 {va_f1:.3f}\")\n",
    "\n",
    "    if va_f1 > best_val_f1:\n",
    "        best_val_f1 = va_f1\n",
    "        best_state = {'model': model.state_dict(), 'epoch': epoch}\n",
    "        patience_ctr = 0\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr > patience:\n",
    "            print('Early stopping.')\n",
    "            break\n",
    "\n",
    "# Save best\n",
    "os.makedirs('checkpoints', exist_ok=True)\n",
    "torch.save(best_state, 'checkpoints/best_resnet18.pt')\n",
    "\n",
    "# Plot curves\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "plt.figure(); plt.plot(history['train_loss']); plt.plot(history['val_loss']); plt.title('Loss'); plt.legend(['train','val']); plt.xlabel('epoch'); plt.ylabel('loss'); plt.savefig('reports/curves_loss.png'); plt.close()\n",
    "plt.figure(); plt.plot(history['train_f1']); plt.plot(history['val_f1']); plt.title('Macro F1'); plt.legend(['train','val']); plt.xlabel('epoch'); plt.ylabel('f1'); plt.savefig('reports/curves_f1.png'); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2d4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model.load_state_dict(best_state['model'])\n",
    "model.eval()\n",
    "\n",
    "all_probs, all_preds, all_targets = [], [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for imgs, labels in test_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        logits = model(imgs)\n",
    "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
    "        preds = probs.argmax(axis=1)\n",
    "        all_probs.append(probs)\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_targets.extend(labels.numpy().tolist())\n",
    "\n",
    "all_probs = np.concatenate(all_probs, axis=0)\n",
    "target_names = test_ds.classes\n",
    "\n",
    "print(\"Classification report (test):\")\n",
    "print(classification_report(all_targets, all_preds, target_names=target_names, digits=4))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_targets, all_preds, labels=list(range(len(target_names))))\n",
    "fig = plt.figure()\n",
    "plt.imshow(cm, interpolation='nearest')\n",
    "plt.title('Confusion Matrix (Test)')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(target_names))\n",
    "plt.xticks(tick_marks, target_names, rotation=45)\n",
    "plt.yticks(tick_marks, target_names)\n",
    "plt.xlabel('Predicted'); plt.ylabel('True')\n",
    "plt.tight_layout()\n",
    "os.makedirs('reports', exist_ok=True)\n",
    "plt.savefig('reports/confusion_matrix.png'); plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b7cffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC-AUC (OvR) and PR curves\n",
    "y_true = np.array(all_targets)\n",
    "Y = np.zeros((len(y_true), len(target_names)))\n",
    "Y[np.arange(len(y_true)), y_true] = 1\n",
    "y_score = all_probs\n",
    "\n",
    "# ROC-AUC macro/micro\n",
    "try:\n",
    "    roc_macro = roc_auc_score(Y, y_score, multi_class='ovr', average='macro')\n",
    "    roc_micro = roc_auc_score(Y, y_score, multi_class='ovr', average='micro')\n",
    "    print(f\"ROC-AUC macro: {roc_macro:.4f} | micro: {roc_micro:.4f}\")\n",
    "except Exception as e:\n",
    "    print(\"ROC-AUC not available:\", e)\n",
    "\n",
    "# Plot ROC per class\n",
    "for i, cname in enumerate(target_names):\n",
    "    fpr, tpr, _ = roc_curve(Y[:, i], y_score[:, i])\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.title(f'ROC Curve – {cname}')\n",
    "    plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "    plt.savefig(f'reports/roc_{cname}.png'); plt.close()\n",
    "\n",
    "# Plot PR per class\n",
    "for i, cname in enumerate(target_names):\n",
    "    prec, rec, _ = precision_recall_curve(Y[:, i], y_score[:, i])\n",
    "    plt.figure()\n",
    "    plt.plot(rec, prec)\n",
    "    plt.title(f'Precision-Recall Curve – {cname}')\n",
    "    plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "    plt.savefig(f'reports/pr_{cname}.png'); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5748c2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grad-CAM visualization on a few test images\n",
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "# Pick the last conv block for ResNet18\n",
    "target_layers = [model.layer4[-1]]\n",
    "\n",
    "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=(device=='cuda'))\n",
    "\n",
    "def tensor_to_rgb(img_tensor):\n",
    "    # img_tensor: (C,H,W), normalized\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std  = np.array([0.229, 0.224, 0.225])\n",
    "    img = img_tensor.numpy().transpose(1,2,0)\n",
    "    img = (img * std) + mean\n",
    "    img = np.clip(img, 0, 1)\n",
    "    return img\n",
    "\n",
    "# Collect a few samples\n",
    "samples = []\n",
    "for i in range(min(12, len(test_ds))):\n",
    "    img, label = test_ds[i]\n",
    "    samples.append((img, label))\n",
    "\n",
    "for i, (img, label) in enumerate(samples):\n",
    "    input_tensor = img.unsqueeze(0).to(device)\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, targets=None)\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    rgb = tensor_to_rgb(img.cpu())\n",
    "    cam_image = show_cam_on_image(rgb, grayscale_cam, use_rgb=True)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.imshow(cam_image)\n",
    "    plt.title(f'Grad-CAM | True: {target_names[label]}')\n",
    "    plt.axis('off')\n",
    "    plt.savefig(f'reports/gradcam_{i}.png'); plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a971ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple reliability diagram & ECE (estimated)\n",
    "def reliability_diagram(probs, y_true, bins=10, savepath='reports/reliability.png'):\n",
    "    confidences = probs.max(axis=1)\n",
    "    predictions = probs.argmax(axis=1)\n",
    "    accuracies = (predictions == y_true).astype(float)\n",
    "\n",
    "    bin_edges = np.linspace(0.0, 1.0, bins+1)\n",
    "    bin_ids = np.digitize(confidences, bin_edges[1:-1], right=True)\n",
    "\n",
    "    bin_acc, bin_conf, bin_count = [], [], []\n",
    "    ece = 0.0\n",
    "    for b in range(bins):\n",
    "        in_bin = (bin_ids == b)\n",
    "        if np.any(in_bin):\n",
    "            acc = accuracies[in_bin].mean()\n",
    "            conf = confidences[in_bin].mean()\n",
    "            cnt = in_bin.sum()\n",
    "            bin_acc.append(acc); bin_conf.append(conf); bin_count.append(cnt)\n",
    "            ece += (cnt/len(confidences)) * abs(acc - conf)\n",
    "        else:\n",
    "            bin_acc.append(0); bin_conf.append(0); bin_count.append(0)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure()\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    # bar centers\n",
    "    centers = np.linspace(1/(2*bins), 1-1/(2*bins), bins)\n",
    "    plt.bar(centers, bin_acc, width=1/bins, alpha=0.6, align='center')\n",
    "    plt.title(f'Reliability Diagram (ECE≈{ece:.3f})')\n",
    "    plt.xlabel('Confidence'); plt.ylabel('Accuracy')\n",
    "    os.makedirs('reports', exist_ok=True)\n",
    "    plt.savefig(savepath); plt.close()\n",
    "    return ece\n",
    "\n",
    "y_true_arr = np.array(all_targets)\n",
    "ece = reliability_diagram(all_probs, y_true_arr, bins=10, savepath='reports/reliability.png')\n",
    "print(f\"Estimated ECE: {ece:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14aec45",
   "metadata": {},
   "source": [
    "## Ethics, Fairness & Next Steps\n",
    "- **Not for clinical use**. Requires radiologist oversight and regulatory approval for real deployment.\n",
    "- **Bias & domain shift**: This dataset may not represent all scanners/populations; test on **external datasets** before relying on it.\n",
    "- **Interpretability**: Grad-CAM should highlight lung regions. If it highlights text markers or borders, that's a red flag for spurious correlations.\n",
    "- **Calibration**: We plotted a simple reliability diagram to understand probability quality. A more robust method is **temperature scaling** on the validation set.\n",
    "- **Improvements**: Try EfficientNet-B0, add **lung segmentation** as a preprocessing step, and report **per-source subgroup metrics** if multiple hospitals are present."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
